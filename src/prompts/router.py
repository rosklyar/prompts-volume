"""Router for prompts generation endpoints."""

from typing import List

import numpy as np
from fastapi import APIRouter, Depends, HTTPException, Query

from src.prompts.services.country_service import CountryService, get_country_service
from src.embeddings.clustering_service import (
    ClusteringService,
    get_clustering_service,
)
from src.embeddings.embeddings_service import EmbeddingsService, get_embeddings_service
from src.embeddings.topic_relevance_filter_service import (
    TopicRelevanceFilterService,
    get_topic_relevance_filter_service,
)
from src.prompts.models import (
    CompanyMetaInfoResponse,
    DBTopicResponse,
    GeneratedPrompts,
    GeneratedTopicResponse,
    TopicsResponse,
)
from src.prompts.services import (
    CompanyMetaInfoService,
    DataForSEOService,
    PromptsGeneratorService,
    get_company_meta_info_service,
    get_dataforseo_service,
    get_prompts_generator_service,
)
from src.utils.keyword_filters import (
    deduplicate_keywords,
    filter_by_brand_exclusion,
    filter_by_word_count,
)
from src.utils.url_validator import extract_domain, validate_url

router = APIRouter(prefix="/prompts/api/v1", tags=["prompts"])


@router.get("/meta-info", response_model=CompanyMetaInfoResponse)
async def get_company_meta_info(
    company_url: str = Query(
        ..., description="Company website URL (e.g., 'moyo.ua', 'https://example.com')"
    ),
    iso_country_code: str = Query(..., description="ISO 3166-1 alpha-2 country code (e.g., 'UA', 'US')"),
    meta_service: CompanyMetaInfoService = Depends(get_company_meta_info_service),
    country_service: CountryService = Depends(get_country_service),
):
    """
    Get company metadata including business domain, topics, and brand variations.

    Uses a 2-call approach to OpenAI:
    1. Detect business domain and language-specific brand variations
    2. Generate domain-specific topics and match with DB topics

    Topics are returned in two categories:
    - matched_topics: Topics found in database (have ID, description, can be referenced)
    - unmatched_topics: Topics generated by LLM (title only, no DB match)

    Args:
        company_url: Company website URL
        iso_country_code: ISO country code to determine languages for brand variations

    Returns:
        CompanyMetaInfoResponse with:
        - business_domain: e-comm or null if not supported
        - topics: Object with matched_topics (DB) and unmatched_topics (generated)
        - brand_variations: List of brand name variations in country-specific languages

    Raises:
        HTTPException 400: Invalid URL or ISO code
        HTTPException 500: Service errors

    Example:
        GET /prompts/api/v1/meta-info?company_url=moyo.ua&iso_country_code=UA

        Response for e-commerce:
        {
            "business_domain": "e-comm",
            "topics": {
                "matched_topics": [
                    {
                        "id": 1,
                        "title": "Смартфони і телефони",
                        "description": "Пошук і покупка телефонів і смартфонів в інтернеті",
                        "business_domain_id": 1,
                        "country_id": 1
                    }
                ],
                "unmatched_topics": [
                    {"title": "Телевізори", "source": "generated"}
                ]
            },
            "brand_variations": ["moyo", "мойо", "MOYO", "Мойо"]
        }

        Response for non-supported:
        {
            "business_domain": null,
            "topics": {"matched_topics": [], "unmatched_topics": []},
            "brand_variations": ["brandname", "БрендНейм"]
        }
    """
    try:
        # Validate URL and extract domain
        await validate_url(company_url)
        domain = extract_domain(company_url)

        # Validate country code
        country = await country_service.get_by_iso_code(iso_country_code)
        if not country:
            raise HTTPException(
                status_code=400, detail=f"Invalid ISO country code: {iso_country_code}"
            )

        # Get company metadata (pass Country object to avoid redundant query)
        meta_info = await meta_service.get_meta_info(domain, country)

        # Convert TopicMatchResult to API response format
        topics_response = TopicsResponse(
            matched_topics=[
                DBTopicResponse.model_validate(topic)
                for topic in meta_info.topics.matched_topics
            ],
            unmatched_topics=[
                GeneratedTopicResponse(
                    title=topic.title,
                    source=topic.source
                )
                for topic in meta_info.topics.unmatched_topics
            ]
        )

        return CompanyMetaInfoResponse(
            business_domain=meta_info.business_domain,
            topics=topics_response,
            brand_variations=meta_info.brand_variations,
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Failed to get company meta info: {str(e)}"
        )

@router.get("/generate", response_model=GeneratedPrompts)
async def generate_prompts(
    company_url: str = Query(..., description="Company website URL (e.g., 'moyo.ua', 'https://example.com')"),
    iso_country_code: str = Query(..., description="ISO 3166-1 alpha-2 country code (e.g., 'UA', 'US')"),
    topics: List[str] = Query(..., description="List of topics/categories (from /meta-info)"),
    brand_variations: List[str] = Query(..., description="List of brand variations (from /meta-info)"),
    dataforseo_service: DataForSEOService = Depends(get_dataforseo_service),
    embeddings_service: EmbeddingsService = Depends(get_embeddings_service),
    prompts_service: PromptsGeneratorService = Depends(get_prompts_generator_service),
    clustering_service: ClusteringService = Depends(get_clustering_service),
    topic_filter_service: TopicRelevanceFilterService = Depends(get_topic_relevance_filter_service),
    country_service: CountryService = Depends(get_country_service),
):
    """
    Generate e-commerce product search prompts from company URL, country, and selected topics.

    Complete automated pipeline:
    1. Validate URL and extract domain
    2. Validate topics and brand variations
    3. Get country info (location, language)
    4. Fetch ALL keywords from DataForSEO (paginated, up to 10k)
    5. Filter keywords (word count ≥3, brand exclusion, dedupe)
    6. Generate embeddings for keywords
    7. Cluster keywords with HDBSCAN
    8. Filter clusters by topic relevance
    9. Generate e-commerce prompts (5 keywords per prompt)

    Args:
        company_url: Company website URL
        iso_country_code: ISO country code for targeting
        topics: List of topics/categories (from /meta-info endpoint)
        brand_variations: List of brand variations (from /meta-info endpoint)

    Returns:
        GeneratedPrompts with topics, clusters, and their prompts

    Raises:
        HTTPException 400: Invalid URL, ISO code, or empty topics/brand_variations
        HTTPException 404: No keywords found
        HTTPException 500: Pipeline errors

    Example:
        GET /prompts/api/v1/generate?company_url=moyo.ua&iso_country_code=UA&topics=Смартфони&topics=Ноутбуки&brand_variations=moyo&brand_variations=мойо
    """
    try:
        # 1. Validate URL and extract domain
        await validate_url(company_url)
        domain = extract_domain(company_url)

        # 2. Validate topics and brand variations
        if not topics:
            raise HTTPException(
                status_code=400, detail="At least one topic must be provided"
            )
        if not brand_variations:
            raise HTTPException(
                status_code=400, detail="At least one brand variation must be provided"
            )

        # 3. Get country info
        country = await country_service.get_by_iso_code(iso_country_code)
        if not country:
            raise HTTPException(
                status_code=400, detail=f"Invalid ISO country code: {iso_country_code}"
            )

        location_name = country.name
        language = country.languages[0].name if country.languages else "English"

        # 4. Fetch ALL keywords with pagination
        keywords = await dataforseo_service.get_all_keywords_for_site(
            target_domain=domain,
            location_name=location_name,
            language=language,
            batch_size=1000,
            max_total=10000,
        )

        if not keywords:
            raise HTTPException(
                status_code=404, detail=f"No keywords found for domain: {domain}"
            )

        # 5. Filter keywords
        filtered_keywords = filter_by_word_count(keywords, min_words=3)
        filtered_keywords = filter_by_brand_exclusion(
            filtered_keywords, brand_variations
        )
        filtered_keywords = deduplicate_keywords(filtered_keywords)

        if not filtered_keywords:
            raise HTTPException(
                status_code=404, detail="No keywords remaining after filtering"
            )

        # 6. Generate embeddings
        keyword_embeddings = embeddings_service.encode_keywords(
            filtered_keywords, batch_size=64
        )

        # 7. Cluster with HDBSCAN
        embeddings_array = np.array([ke.embedding for ke in keyword_embeddings])

        clustering_result = clustering_service.cluster(
            keywords=filtered_keywords,
            embeddings=embeddings_array,
            min_cluster_size=5,
            min_samples=5,
            cluster_selection_epsilon=0.0,
        )

        # 8. Filter clusters by topic relevance
        filtered_by_topic = topic_filter_service.filter_by_topics(
            clustering_result=clustering_result,
            topics=topics,
            similarity_threshold=0.7,
            min_relevant_ratio=0.5,
        )

        # 9. Remove empty topics and generate prompts
        topics_with_clusters = {
            topic: clusters for topic, clusters in filtered_by_topic.items() if clusters
        }

        if not topics_with_clusters:
            raise HTTPException(
                status_code=404, detail="No relevant topic clusters found"
            )

        result = await prompts_service.generate_prompts(
            topics_with_clusters=topics_with_clusters, number_of_keywords_for_prompt=5
        )

        return result

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Failed to generate prompts: {str(e)}"
        )
